{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KORALLLL/MTUCI_EMNIST/blob/main/bagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/KORALLLL/MTUCI_EMNIST.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R6-mCc-naeh",
        "outputId": "1554c1f9-aa7a-4236-9267-de8f00491af6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MTUCI_EMNIST'...\n",
            "remote: Enumerating objects: 36671, done.\u001b[K\n",
            "remote: Counting objects: 100% (13031/13031), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12853/12853), done.\u001b[K\n",
            "remote: Total 36671 (delta 298), reused 12831 (delta 164), pack-reused 23640\u001b[K\n",
            "Receiving objects: 100% (36671/36671), 140.59 MiB | 13.77 MiB/s, done.\n",
            "Resolving deltas: 100% (583/583), done.\n",
            "Filtering content: 100% (6/6), 192.63 MiB | 59.18 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prepairing to ansamblinh"
      ],
      "metadata": {
        "id": "LnTABRChwT7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N8gtykPxnNE1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "from MTUCI_EMNIST.models.alex import LeNetDropOut as model_alex\n",
        "from MTUCI_EMNIST.models.artem import Net5 as model_artem\n",
        "from MTUCI_EMNIST.models.gleb import LeNet as model_gleb\n",
        "from MTUCI_EMNIST.models.kirill import Model5 as model_kirill\n",
        "from MTUCI_EMNIST.models.nastya import Lenet4 as model_nastya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HWUr2CFQnNE3"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "file = open('MTUCI_EMNIST/dataset.pkl', 'rb')\n",
        "test_dataset = pickle.load(file)\n",
        "file.close()\n",
        "\n",
        "test_data = test_dataset['data'].numpy()\n",
        "test_data = np.flip(test_data, axis = 3)\n",
        "test_data = np.rot90(test_data, k=1, axes=(2,3))\n",
        "test_data = 1 - test_data\n",
        "test_data = torch.from_numpy(test_data).float().to(device)\n",
        "test_labels = test_dataset['targets'].to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO09LyW1nNE8"
      },
      "outputs": [],
      "source": [
        "# # путь к исходному файлу\n",
        "# input_file_path = 'weights\\Artem_ModelParameters0.8530000448226929.pth'\n",
        "\n",
        "# # пути для двух выходных файлов\n",
        "# output_file_path_part1 = 'your_model_weights_part1.pth'\n",
        "# output_file_path_part2 = 'your_model_weights_part2.pth'\n",
        "\n",
        "# # размер каждой части (в байтах)\n",
        "# chunk_size = 100000000  # н100 МБ\n",
        "\n",
        "# with open(input_file_path, 'rb') as input_file:\n",
        "#     #  данные из исходного файла\n",
        "#     data = input_file.read()\n",
        "\n",
        "#     #  данные на две части\n",
        "#     data_part1 = data[:chunk_size]\n",
        "#     data_part2 = data[chunk_size:]\n",
        "\n",
        "#     #  данные в выходные файлы\n",
        "#     with open(output_file_path_part1, 'wb') as output_file_part1:\n",
        "#         output_file_part1.write(data_part1)\n",
        "\n",
        "#     with open(output_file_path_part2, 'wb') as output_file_part2:\n",
        "#         output_file_part2.write(data_part2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o8pQEDK9nNE_"
      },
      "outputs": [],
      "source": [
        "def combine_files(input_file_path_part1, input_file_path_part2):\n",
        "    with open(input_file_path_part1, 'rb') as input_file_part1, \\\n",
        "         open(input_file_path_part2, 'rb') as input_file_part2:\n",
        "\n",
        "        #  данные из первой и второй частей\n",
        "        data_part1 = input_file_part1.read()\n",
        "        data_part2 = input_file_part2.read()\n",
        "\n",
        "        # Объединяем данные\n",
        "        combined_data = data_part1 + data_part2\n",
        "\n",
        "    return combined_data\n",
        "\n",
        "# пути для ваших файлов\n",
        "input_file_path_part1 = '/content/MTUCI_EMNIST/weights/your_model_weights_part1.pth'\n",
        "input_file_path_part2 = '/content/MTUCI_EMNIST/weights/your_model_weights_part2.pth'\n",
        "\n",
        "# функцию для объединения данных в одну переменную\n",
        "combined_data = combine_files(input_file_path_part1, input_file_path_part2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Artem net"
      ],
      "metadata": {
        "id": "VsQ9UqQQt1gr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Dc-d9s0AnNFB"
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "import gc\n",
        "\n",
        "net1 = model_artem().to(device)\n",
        "net1.load_state_dict(torch.load(BytesIO(combined_data), map_location=device))\n",
        "net1.eval()\n",
        "with torch.no_grad():\n",
        "  test_preds = torch.sigmoid(net1.forward(test_data)).float().cpu().data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(((test_preds.argmax(dim=1) == test_labels).float().mean().cpu().data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo_9kYTHtgFE",
        "outputId": "98a663df-f8d3-4ace-b8a6-8c82522cbb71"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8534)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lrKLi-xXnNFB"
      },
      "outputs": [],
      "source": [
        "result = test_preds*0.8534"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(((result.argmax(dim=1) == test_labels).float().mean().cpu().data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW4JG6w4zkx9",
        "outputId": "a8d68e16-3e28-4446-af63-71990c83f034"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8534)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del net1\n",
        "del test_preds\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ODO_YLptmuZ",
        "outputId": "e963ab7b-99cc-4994-8c1f-88eb6707468a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sasha net"
      ],
      "metadata": {
        "id": "VORHn0souDIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = model_alex(0.1).to(device)\n",
        "net.load_state_dict(torch.load('/content/MTUCI_EMNIST/weights/Sasha_ModelParameters0.8540592193603516.pth', map_location=device))\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "  test_preds = torch.sigmoid(net.forward(test_data)).float().cpu().data\n",
        "print(((test_preds.argmax(dim=1) == test_labels).float().mean().cpu().data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rviLLbDjuGFi",
        "outputId": "03876003-c0fa-4cf0-c1e6-774f0b6b0da9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8539)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result += (test_preds*0.8539)"
      ],
      "metadata": {
        "id": "KbVe3oB3v_y5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(((result.argmax(dim=1) == test_labels).float().mean().cpu().data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zwh1_Ymzltz",
        "outputId": "3695fa22-22f2-43d1-c2d4-25cafc71e10b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8665)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del net\n",
        "del test_preds\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEjovXlfwFyh",
        "outputId": "c2208c08-d35f-492c-f2b8-098e763a02a8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nastya net"
      ],
      "metadata": {
        "id": "Nzvdjd9TwM0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = model_nastya().to(device)\n",
        "net.load_state_dict(torch.load('/content/MTUCI_EMNIST/weights/Nastya_ModelParameters0.8714902997016907.pth', map_location=device))\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "  test_preds = torch.sigmoid(net.forward(test_data)).float().cpu().data\n",
        "print(((test_preds.argmax(dim=1) == test_labels).float().mean().cpu().data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXLBq32dwRqU",
        "outputId": "f812d8b2-f27f-4d99-d24f-c9b4dc0b4b97"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8718)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result += (test_preds*0.8718)"
      ],
      "metadata": {
        "id": "CKmkJ-pkwxup"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(((result.argmax(dim=1) == test_labels).float().mean().cpu().data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOJf8A5TzmZv",
        "outputId": "4f71ab8a-4706-40c1-e5b6-a04687ed0980"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8765)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del net\n",
        "del test_preds\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sdeThjXw-I5",
        "outputId": "97385a1e-0db1-4e13-fab0-d6a2d6a97e91"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gleb net"
      ],
      "metadata": {
        "id": "mTEgsbDmw7H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = model_gleb().to(device)\n",
        "net.load_state_dict(torch.load('/content/MTUCI_EMNIST/weights/Gleb_ModelParameters0.8664226531982422.pth', map_location=device))\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "  test_preds = torch.sigmoid(net.forward(test_data)).float().cpu().data\n",
        "print(((test_preds.argmax(dim=1) == test_labels).float().mean().cpu().data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtAs3SGrw_mJ",
        "outputId": "bc0804e1-73b2-4bd3-dc9b-f9b15007e193"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8667)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result += (test_preds*0.8667)"
      ],
      "metadata": {
        "id": "t4_llNC-xd-q"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(((result.argmax(dim=1) == test_labels).float().mean().cpu().data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kUrqRYxznEk",
        "outputId": "5611a494-9a9e-4e4c-eeca-9434a72ae9c9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8793)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del net\n",
        "del test_preds\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BICnuJYTxhe0",
        "outputId": "29dd5f6f-fb9b-4711-a83b-aa595a199662"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kirill Net"
      ],
      "metadata": {
        "id": "AjtGPdvtxqy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = model_kirill().to(device)\n",
        "net.load_state_dict(torch.load('/content/MTUCI_EMNIST/weights/Kirill_ModelParameters0.8665027618408203(1).pth', map_location=device))\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "  test_preds = torch.sigmoid(net.forward(test_data)).float().cpu().data\n",
        "print(((test_preds.argmax(dim=1) == test_labels).float().mean().cpu().data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnnNFv4BxiNo",
        "outputId": "e0e5451d-1b91-4ab1-8367-c5c4e93bd721"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8671)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result += (test_preds*0.8671)"
      ],
      "metadata": {
        "id": "nugezTkdyh7d"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# scoring"
      ],
      "metadata": {
        "id": "PQKXafvJylCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(((result.argmax(dim=1) == test_labels).float().mean().cpu().data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB8VYaz9yoCI",
        "outputId": "4a07bc34-5241-480b-b1a1-f2e4b2bfd73d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8815)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}