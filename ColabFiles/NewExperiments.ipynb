{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOX1OoFMTMdpBKAqT6VxlEZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KORALLLL/MTUCI_EMNIST/blob/Sasha/ColabFiles/NewExperiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm_notebook as bar\n",
        "import pickle\n",
        "import torchvision.datasets\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "p_6wavHCYftr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/KORALLLL/MTUCI_EMNIST.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCqA9w1wZggj",
        "outputId": "9d558315-e3b2-4b57-c355-a615e958633a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MTUCI_EMNIST'...\n",
            "remote: Enumerating objects: 36499, done.\u001b[K\n",
            "remote: Counting objects: 100% (12859/12859), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12692/12692), done.\u001b[K\n",
            "remote: Total 36499 (delta 186), reused 12804 (delta 159), pack-reused 23640\u001b[K\n",
            "Receiving objects: 100% (36499/36499), 128.89 MiB | 11.92 MiB/s, done.\n",
            "Resolving deltas: 100% (471/471), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emnist_train = torchvision.datasets.EMNIST('./', split='letters', download = True, train = True)\n",
        "mnist_train = torchvision.datasets.EMNIST('./', split='mnist', download = True, train = True)\n",
        "emnist_val = torchvision.datasets.EMNIST('./', split='letters', download = True, train = False)\n",
        "mnist_val = torchvision.datasets.EMNIST('./', split='mnist', download = True, train = False)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "emnist_train_data = emnist_train.data\n",
        "mnist_train_data = mnist_train.data\n",
        "train_data = torch.cat([emnist_train_data[:24960], mnist_train_data[:12000]], dim=0).float().unsqueeze(1).to(device) / 255\n",
        "\n",
        "emnist_val_data = emnist_val.data\n",
        "mnist_val_data = mnist_val.data\n",
        "val_data = torch.cat([emnist_val_data, mnist_val_data], dim=0).float().unsqueeze(1).to(device) / 255\n",
        "\n",
        "temp_emnist_train_labels = emnist_train.targets[:24960]\n",
        "emnist_train_labels = []\n",
        "\n",
        "temp_emnist_val_labels = emnist_val.targets\n",
        "emnist_val_labels = []\n",
        "\n",
        "for i in range(len(temp_emnist_train_labels)):\n",
        "  if temp_emnist_train_labels[i]==15:\n",
        "    emnist_train_labels.append(torch.tensor(0))\n",
        "  elif temp_emnist_train_labels[i]>15:\n",
        "    emnist_train_labels.append(temp_emnist_train_labels[i]+8)\n",
        "  else:\n",
        "    emnist_train_labels.append(temp_emnist_train_labels[i]+9)\n",
        "\n",
        "for i in range(len(temp_emnist_val_labels)):\n",
        "  if temp_emnist_val_labels[i]==15:\n",
        "    emnist_val_labels.append(torch.tensor(0))\n",
        "  elif temp_emnist_val_labels[i]>15:\n",
        "    emnist_val_labels.append(temp_emnist_val_labels[i] + 8)\n",
        "  else:\n",
        "    emnist_val_labels.append(temp_emnist_val_labels[i]+9)\n",
        "\n",
        "mnist_train_labels = mnist_train.targets\n",
        "train_labels = torch.cat([torch.stack(emnist_train_labels[:24960]), mnist_train_labels[:12000]], dim=0).to(device)\n",
        "\n",
        "mnist_val_labels = mnist_val.targets\n",
        "val_labels = torch.cat([torch.stack(emnist_val_labels), mnist_val_labels], dim=0).to(device)\n",
        "\n",
        "\n",
        "file = open('MTUCI_EMNIST/dataset.pkl', 'rb')\n",
        "test_dataset = pickle.load(file)\n",
        "file.close()\n",
        "\n",
        "test_data = test_dataset['data'].numpy()\n",
        "test_data = np.flip(test_data, axis = 3)\n",
        "test_data = np.rot90(test_data, k=1, axes=(2,3))\n",
        "test_data = 1 - test_data\n",
        "test_data = torch.from_numpy(test_data).float().to(device)\n",
        "test_labels = test_dataset['targets'].to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx9kRN42ZhOT",
        "outputId": "0704e532-f238-46cf-c3fa-41af59d425f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to ./EMNIST/raw/gzip.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 561753746/561753746 [00:07<00:00, 73689237.41it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./EMNIST/raw/gzip.zip to ./EMNIST/raw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Лучшая сеть по итогам экспериментов\n"
      ],
      "metadata": {
        "id": "NzANzM82SSIQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDqEEikfSNNj"
      },
      "outputs": [],
      "source": [
        "class LeNetMaxAvg(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNetMaxAvg, self).__init__()\n",
        "\n",
        "    self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=2,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.act1 = torch.nn.Tanh()\n",
        "    self.conv2 = torch.nn.Conv2d(in_channels=2, out_channels=4,\n",
        "                                 kernel_size=3, padding=1)\n",
        "\n",
        "    self.act2 = torch.nn.Tanh()\n",
        "    self.conv3 = torch.nn.Conv2d(in_channels=4, out_channels=8,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.act3 = torch.nn.Tanh()\n",
        "    self.conv4 = torch.nn.Conv2d(in_channels=8, out_channels=16,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.act4 = torch.nn.Tanh()\n",
        "    self.conv5 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.act5 = torch.nn.Tanh()\n",
        "    self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.act6 = torch.nn.Tanh()\n",
        "\n",
        "\n",
        "    self.conv6 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.act7 = torch.nn.Tanh()\n",
        "    self.conv7 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.act8 = torch.nn.Tanh()\n",
        "    self.conv8 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.act9 = torch.nn.Tanh()\n",
        "    self.conv9 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=0)\n",
        "    self.act10 = torch.nn.Tanh()\n",
        "    self.conv10 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=0)\n",
        "    self.act11 = torch.nn.Tanh()\n",
        "    self.pool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    self.act12 = torch.nn.Tanh()\n",
        "\n",
        "    self.fc1 = torch.nn.Linear(5 * 5 * 16, 120)\n",
        "    self.act13 = torch.nn.ReLU()\n",
        "    self.fc2 = torch.nn.Linear(120, 84)\n",
        "    self.act14 = torch.nn.ReLU()\n",
        "    self.fc3 = torch.nn.Linear(84, 35)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.act1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.act2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.act3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.act4(x)\n",
        "    x = self.conv5(x)\n",
        "    x = self.act5(x)\n",
        "    x = self.pool1(x)\n",
        "    x = self.act6(x)\n",
        "\n",
        "    x = self.conv6(x)\n",
        "    x = self.act7(x)\n",
        "    x = self.conv7(x)\n",
        "    x = self.act8(x)\n",
        "    x = self.conv8(x)\n",
        "    x = self.act9(x)\n",
        "    x = self.conv9(x)\n",
        "    x = self.act10(x)\n",
        "    x = self.conv10(x)\n",
        "    x = self.act11(x)\n",
        "    x = self.pool2(x)\n",
        "    x = self.act12(x)\n",
        "\n",
        "    x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = self.act13(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.act14(x)\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Добавление слоев батч-нормализации"
      ],
      "metadata": {
        "id": "wPiUvEF_ZzCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNetBatch(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNetBatch, self).__init__()\n",
        "\n",
        "    self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=2,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.batch_norm1 = torch.nn.BatchNorm2d(2)\n",
        "    self.act1 = torch.nn.Tanh()\n",
        "    self.conv2 = torch.nn.Conv2d(in_channels=2, out_channels=4,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.batch_norm2 = torch.nn.BatchNorm2d(4)\n",
        "\n",
        "    self.act2 = torch.nn.Tanh()\n",
        "    self.conv3 = torch.nn.Conv2d(in_channels=4, out_channels=8,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.batch_norm3 = torch.nn.BatchNorm2d(8)\n",
        "    self.act3 = torch.nn.Tanh()\n",
        "    self.conv4 = torch.nn.Conv2d(in_channels=8, out_channels=16,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.batch_norm4 = torch.nn.BatchNorm2d(16)\n",
        "    self.act4 = torch.nn.Tanh()\n",
        "    self.conv5 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.batch_norm5 = torch.nn.BatchNorm2d(16)\n",
        "    self.act5 = torch.nn.Tanh()\n",
        "    self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.act6 = torch.nn.Tanh()\n",
        "\n",
        "\n",
        "    self.conv6 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.batch_norm6 = torch.nn.BatchNorm2d(16)\n",
        "    self.act7 = torch.nn.Tanh()\n",
        "    self.conv7 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.batch_norm7 = torch.nn.BatchNorm2d(16)\n",
        "    self.act8 = torch.nn.Tanh()\n",
        "    self.conv8 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.batch_norm8 = torch.nn.BatchNorm2d(16)\n",
        "    self.act9 = torch.nn.Tanh()\n",
        "    self.conv9 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=0)\n",
        "    self.batch_norm9 = torch.nn.BatchNorm2d(16)\n",
        "    self.act10 = torch.nn.Tanh()\n",
        "    self.conv10 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=0)\n",
        "    self.batch_norm10 = torch.nn.BatchNorm2d(16)\n",
        "    self.act11 = torch.nn.Tanh()\n",
        "    self.pool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    self.act12 = torch.nn.Tanh()\n",
        "\n",
        "    self.fc1 = torch.nn.Linear(5 * 5 * 16, 120)\n",
        "    self.act13 = torch.nn.ReLU()\n",
        "    self.fc2 = torch.nn.Linear(120, 84)\n",
        "    self.act14 = torch.nn.ReLU()\n",
        "    self.fc3 = torch.nn.Linear(84, 35)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.batch_norm1(x)\n",
        "    x = self.act1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.batch_norm2(x)\n",
        "    x = self.act2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.batch_norm3(x)\n",
        "    x = self.act3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.batch_norm4(x)\n",
        "    x = self.act4(x)\n",
        "    x = self.conv5(x)\n",
        "    x = self.batch_norm5(x)\n",
        "    x = self.act5(x)\n",
        "    x = self.pool1(x)\n",
        "    x = self.act6(x)\n",
        "\n",
        "    x = self.conv6(x)\n",
        "    x = self.batch_norm6(x)\n",
        "    x = self.act7(x)\n",
        "    x = self.conv7(x)\n",
        "    x = self.batch_norm7(x)\n",
        "    x = self.act8(x)\n",
        "    x = self.conv8(x)\n",
        "    x = self.batch_norm8(x)\n",
        "    x = self.act9(x)\n",
        "    x = self.conv9(x)\n",
        "    x = self.batch_norm9(x)\n",
        "    x = self.act10(x)\n",
        "    x = self.conv10(x)\n",
        "    x = self.batch_norm10(x)\n",
        "    x = self.act11(x)\n",
        "    x = self.pool2(x)\n",
        "    x = self.act12(x)\n",
        "\n",
        "    x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = self.act13(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.act14(x)\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "gqLz_B1yTI7E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Добавление дропаута"
      ],
      "metadata": {
        "id": "iSLuHX2qgUNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNetMaxAvg(torch.nn.Module):\n",
        "  def __init__(self, dropout_rate):\n",
        "    super(LeNetMaxAvg, self).__init__()\n",
        "\n",
        "    self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=2,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.act1 = torch.nn.Tanh()\n",
        "    self.dropout1 = torch.nn.Dropout(p=dropout_rate)\n",
        "    self.conv2 = torch.nn.Conv2d(in_channels=2, out_channels=4,\n",
        "                                 kernel_size=3, padding=1)\n",
        "\n",
        "    self.act2 = torch.nn.Tanh()\n",
        "    self.dropout2 = torch.nn.Dropout(p=dropout_rate)\n",
        "    self.conv3 = torch.nn.Conv2d(in_channels=4, out_channels=8,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.act3 = torch.nn.Tanh()\n",
        "    self.dropout3 = torch.nn.Dropout(p=dropout_rate)\n",
        "    self.conv4 = torch.nn.Conv2d(in_channels=8, out_channels=16,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.act4 = torch.nn.Tanh()\n",
        "    self.dropout4 = torch.nn.Dropout(p=dropout_rate)\n",
        "    self.conv5 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.act5 = torch.nn.Tanh()\n",
        "    self.dropout5 = torch.nn.Dropout(p=dropout_rate)\n",
        "    self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.act6 = torch.nn.Tanh()\n",
        "\n",
        "\n",
        "    self.conv6 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.act7 = torch.nn.Tanh()\n",
        "    self.dropout6 = torch.nn.Dropout(p=dropout_rate)\n",
        "    self.conv7 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.act8 = torch.nn.Tanh()\n",
        "    self.dropout7 = torch.nn.Dropout(p=dropout_rate)\n",
        "    self.conv8 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=1)\n",
        "    self.act9 = torch.nn.Tanh()\n",
        "    self.dropout8 = torch.nn.Dropout(p=dropout_rate)\n",
        "    self.conv9 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=0)\n",
        "    self.act10 = torch.nn.Tanh()\n",
        "    self.dropout9 = torch.nn.Dropout(p=dropout_rate)\n",
        "    self.conv10 = torch.nn.Conv2d(in_channels=16, out_channels=16,\n",
        "                                 kernel_size=3, padding=0)\n",
        "    self.act11 = torch.nn.Tanh()\n",
        "    self.dropout10 = torch.nn.Dropout(p=dropout_rate)\n",
        "    self.pool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    self.act12 = torch.nn.Tanh()\n",
        "\n",
        "    self.fc1 = torch.nn.Linear(5 * 5 * 16, 120)\n",
        "    self.act13 = torch.nn.ReLU()\n",
        "    self.fc2 = torch.nn.Linear(120, 84)\n",
        "    self.act14 = torch.nn.ReLU()\n",
        "    self.fc3 = torch.nn.Linear(84, 35)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.act1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.act2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.act3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.act4(x)\n",
        "    x = self.conv5(x)\n",
        "    x = self.act5(x)\n",
        "    x = self.pool1(x)\n",
        "    x = self.act6(x)\n",
        "\n",
        "    x = self.conv6(x)\n",
        "    x = self.act7(x)\n",
        "    x = self.conv7(x)\n",
        "    x = self.act8(x)\n",
        "    x = self.conv8(x)\n",
        "    x = self.act9(x)\n",
        "    x = self.conv9(x)\n",
        "    x = self.act10(x)\n",
        "    x = self.conv10(x)\n",
        "    x = self.act11(x)\n",
        "    x = self.pool2(x)\n",
        "    x = self.act12(x)\n",
        "\n",
        "    x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = self.act13(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.act14(x)\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "TBVZDjAjgRqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Цикл обучения"
      ],
      "metadata": {
        "id": "SVoN98hrgbdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for j in range(1):\n",
        "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "  lenet5 = LeNetBatch().to(device)\n",
        "  loss = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(lenet5.parameters(), lr=1.0e-3)\n",
        "  batch_size = 1120\n",
        "  test_accuracy_history = []\n",
        "  test_loss_history = []\n",
        "\n",
        "  for epoch in range(100):\n",
        "    order = np.random.permutation(len(train_data))\n",
        "    for start_index in range(0, len(train_data), batch_size):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      batch_indexes = order[start_index:start_index + batch_size]\n",
        "      train_batch = train_data[batch_indexes].to(device)\n",
        "      label_batch = train_labels[batch_indexes].to(device)\n",
        "\n",
        "      preds = lenet5.forward(train_batch)\n",
        "\n",
        "      loss_value = loss(preds, label_batch)\n",
        "      loss_value.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "  test_preds = lenet5.forward(test_data)\n",
        "  test_loss_history.append(loss(test_preds, test_labels).data.cpu())\n",
        "\n",
        "  accuracy = (test_preds.argmax(dim=1) == test_labels).float().mean().data.cpu()\n",
        "  test_accuracy_history.append(accuracy)\n",
        "  print(accuracy)\n",
        "  print(\"-----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTbUqwxFcdeQ",
        "outputId": "6f0c9507-499a-49c2-ef1b-92db62a59160"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7280)\n",
            "-----\n"
          ]
        }
      ]
    }
  ]
}