{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOZ/iaA2D9I3PXdGGmFv3dt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KORALLLL/MTUCI_EMNIST/blob/main/BaseLine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# your number(!!!!!!!!!!!!!!)"
      ],
      "metadata": {
        "id": "t0HppbEN3Mh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 - Kirill\n",
        "# 2 - Gleb\n",
        "# 3 - Artem\n",
        "# 4 - Sasha\n",
        "# 5 - Nastya\n",
        "\n",
        "number = ###################################\n",
        "\n",
        "batch_size = ############################ 43120 % your_batch_size ==0 !!!!!!!!!!!!!!!!\n",
        "\n",
        "names = {1:\"Kirill\", 2:\"Gleb\", 3:\"Artem\", 4:\"Sasha\", 5:\"Nastya\"}\n",
        "\n",
        "print(\"Hello, \", names[number])"
      ],
      "metadata": {
        "id": "hF350AFK2_ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HyperParameters (!!!!!!!!!!!!!!!!!!)"
      ],
      "metadata": {
        "id": "qvwsUFJtYLNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please, tell about your module and chosen parameters"
      ],
      "metadata": {
        "id": "uq48jq_kYOM7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module importation"
      ],
      "metadata": {
        "id": "yfQeFHM8YwVB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhqIzQU-XzDP"
      },
      "outputs": [],
      "source": [
        "!pip install torch_optimizer\n",
        "!pip install gTTS\n",
        "!git clone https://github.com/KORALLLL/MTUCI_EMNIST.git\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "from torch_optimizer import AdaBound\n",
        "\n",
        "from tqdm.notebook import tqdm as bar\n",
        "import pickle\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from matplotlib import colors, pyplot as plt\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "import gc\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import random\n",
        "import itertools\n",
        "from collections import Counter\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notificator"
      ],
      "metadata": {
        "id": "AqDyiAFsZAkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def send_notification(message=\"Операция завершена\"):\n",
        "    # Создаем объект gTTS с текстом уведомления\n",
        "    tts = gTTS(text=message, lang='ru')\n",
        "    # Сохраняем генерированный аудиофайл\n",
        "    tts.save('notification.mp3')\n",
        "    # Воспроизводим уведомление\n",
        "    return Audio(\"notification.mp3\", autoplay=True)"
      ],
      "metadata": {
        "id": "YxKHV9XvZCK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset preparation"
      ],
      "metadata": {
        "id": "xeitKt6iZcwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "etrain_start = 24960*(number-1)\n",
        "etrain_end = 24960*number\n",
        "eval_start = 4160*(number-1)\n",
        "eval_end = 4160*number\n",
        "\n",
        "train_start = 12000*(number-1)\n",
        "train_end = 12000*number\n",
        "val_start= 2000*(number-1)\n",
        "val_end = 2000*number\n",
        "\n",
        "emnist_train = torchvision.datasets.EMNIST('./', split='letters', download = True, train = True)\n",
        "mnist_train = torchvision.datasets.EMNIST('./', split='mnist', download = True, train = True)\n",
        "emnist_val = torchvision.datasets.EMNIST('./', split='letters', download = True, train = False)\n",
        "mnist_val = torchvision.datasets.EMNIST('./', split='mnist', download = True, train = False)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "emnist_train_data = emnist_train.data\n",
        "mnist_train_data = mnist_train.data\n",
        "train_data = torch.cat([emnist_train_data[etrain_start:etrain_end], mnist_train_data[train_start:train_end]], dim=0).float().unsqueeze(1).to(device) / 255\n",
        "\n",
        "emnist_val_data = emnist_val.data\n",
        "mnist_val_data = mnist_val.data\n",
        "val_data = torch.cat([emnist_val_data[eval_start:eval_end], mnist_val_data[val_start:val_end]], dim=0).float().unsqueeze(1).to(device) / 255\n",
        "\n",
        "temp_emnist_train_labels = emnist_train.targets[etrain_start:etrain_end]\n",
        "emnist_train_labels = []\n",
        "\n",
        "temp_emnist_val_labels = emnist_val.targets[eval_start:eval_end]\n",
        "emnist_val_labels = []\n",
        "\n",
        "for i in range(len(temp_emnist_train_labels)):\n",
        "  if temp_emnist_train_labels[i]==15:\n",
        "    emnist_train_labels.append(torch.tensor(0))\n",
        "  elif temp_emnist_train_labels[i]>15:\n",
        "    emnist_train_labels.append(temp_emnist_train_labels[i]+8)\n",
        "  else:\n",
        "    emnist_train_labels.append(temp_emnist_train_labels[i]+9)\n",
        "\n",
        "for i in range(len(temp_emnist_val_labels)):\n",
        "  if temp_emnist_val_labels[i]==15:\n",
        "    emnist_val_labels.append(torch.tensor(0))\n",
        "  elif temp_emnist_val_labels[i]>15:\n",
        "    emnist_val_labels.append(temp_emnist_val_labels[i] + 8)\n",
        "  else:\n",
        "    emnist_val_labels.append(temp_emnist_val_labels[i]+9)\n",
        "\n",
        "mnist_train_labels = mnist_train.targets\n",
        "train_labels = torch.cat([torch.stack(emnist_train_labels), mnist_train_labels[train_start:train_end]], dim=0).to(device)\n",
        "\n",
        "mnist_val_labels = mnist_val.targets\n",
        "val_labels = torch.cat([torch.stack(emnist_val_labels), mnist_val_labels[val_start:val_end]], dim=0).to(device)\n",
        "\n",
        "\n",
        "file = open('MTUCI_EMNIST/dataset.pkl', 'rb')\n",
        "test_dataset = pickle.load(file)\n",
        "file.close()\n",
        "\n",
        "test_data = test_dataset['data'].numpy()\n",
        "test_data = np.flip(test_data, axis = 3)\n",
        "test_data = np.rot90(test_data, k=1, axes=(2,3))\n",
        "test_data = 1 - test_data\n",
        "test_data = torch.from_numpy(test_data).float().to(device)\n",
        "test_labels = test_dataset['targets'].to(device)\n"
      ],
      "metadata": {
        "id": "_Xdwi4rIhQt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataSet analysis"
      ],
      "metadata": {
        "id": "KXRAaA5vxCXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = {0: '0', 1: '1',2: '2',3: '3',4: '4',5: '5',6: '6',7: '7',8: '8',9: '9',10: 'a',11: 'b',12: 'c',13: 'd',\n",
        " 14: 'e',15: 'f',16: 'g',17: 'h',18: 'i',19: 'j',20: 'k',21: 'l',22: 'm',23: 'n',24: 'p',25: 'q',26: 'r',27: 's',28: 't',29: 'u',\n",
        " 30: 'v',31: 'w',32: 'x',33: 'y',34: 'z','o': 0}"
      ],
      "metadata": {
        "id": "T7IfO4Iexzk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([converter[int(i)] for i in torch.cat([train_labels,val_labels]).cpu()], columns = [\"label\"])\n",
        "df['count'] = 1\n",
        "df = df.groupby(\"label\").count().sort_values('count', ascending=False)\n",
        "plt.figure(figsize=(16., 6.))\n",
        "sns.barplot(x=df.index, y='count', data=df)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3FNnM4IjZusM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_indexes = [random.randint(0, len(val_data)) for i in range(16)]\n",
        "\n",
        "\n",
        "r, c = 4, 4\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i in range(16):\n",
        "    fig.add_subplot(4,4,i+1)\n",
        "    plt.imshow(val_data[random_indexes[i]][0].flip(dims=[1]).rot90(1, [0,1]).cpu(), cmap='gray')\n",
        "    plt.title(converter[int(val_labels[random_indexes[i]])])\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "m5Nqi3MBtrcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## augmentations"
      ],
      "metadata": {
        "id": "RfxfNu9mzaO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### perspectiver"
      ],
      "metadata": {
        "id": "4PLJPMJU0_Xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perspectiver = transforms.RandomPerspective(distortion_scale=0.5, p=1.)\n",
        "random_indexes = [random.randint(0, len(val_data)) for i in range(16)]\n",
        "\n",
        "\n",
        "r, c = 4, 4\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "for i in range(8):\n",
        "    fig.add_subplot(4,4,i+1)\n",
        "    image = val_data[random_indexes[i]]\n",
        "    plt.imshow(perspectiver(image)[0].flip(dims=[1]).rot90(1, [0,1]).cpu(), cmap='gray')\n",
        "    plt.title(converter[int(val_labels[random_indexes[i]])])\n",
        "    plt.axis('off')\n",
        "\n",
        "    fig.add_subplot(4,4,i+9)\n",
        "    plt.imshow(image[0].flip(dims=[1]).rot90(1, [0,1]).cpu(), cmap='gray')\n",
        "    plt.title(converter[int(val_labels[random_indexes[i]])])\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "uca8uYSZ1OUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### rotater"
      ],
      "metadata": {
        "id": "JC7UcTRr1DGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotater = transforms.RandomRotation(degrees=(-20,20))\n",
        "random_indexes = [random.randint(0, len(val_data)) for i in range(16)]\n",
        "\n",
        "\n",
        "r, c = 4, 4\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "for i in range(8):\n",
        "    fig.add_subplot(4,4,i+1)\n",
        "    image = val_data[random_indexes[i]]\n",
        "    plt.imshow(rotater(image)[0].flip(dims=[1]).rot90(1, [0,1]).cpu(), cmap='gray')\n",
        "    plt.title(converter[int(val_labels[random_indexes[i]])])\n",
        "    plt.axis('off')\n",
        "\n",
        "    fig.add_subplot(4,4,i+9)\n",
        "    plt.imshow(image[0].flip(dims=[1]).rot90(1, [0,1]).cpu(), cmap='gray')\n",
        "    plt.title(converter[int(val_labels[random_indexes[i]])])\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "_1idM85p3BdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### shifter"
      ],
      "metadata": {
        "id": "R9Wy5z-c1E1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shifter = transforms.RandomAffine(0, translate = (3/28,3/28))\n",
        "random_indexes = [random.randint(0, len(val_data)) for i in range(16)]\n",
        "\n",
        "\n",
        "r, c = 4, 4\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "for i in range(8):\n",
        "    fig.add_subplot(4,4,i+1)\n",
        "    image = val_data[random_indexes[i]]\n",
        "    plt.imshow(shifter(image)[0].flip(dims=[1]).rot90(1, [0,1]).cpu(), cmap='gray')\n",
        "    plt.title(converter[int(val_labels[random_indexes[i]])])\n",
        "    plt.axis('off')\n",
        "\n",
        "    fig.add_subplot(4,4,i+9)\n",
        "    plt.imshow(image[0].flip(dims=[1]).rot90(1, [0,1]).cpu(), cmap='gray')\n",
        "    plt.title(converter[int(val_labels[random_indexes[i]])])\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "GHHJQRWZ4SP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### compressor"
      ],
      "metadata": {
        "id": "S4jofRyb1Hb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compressor = torchvision.transforms.RandomAffine(0, scale = (0.7, 0.9))\n",
        "\n",
        "r, c = 4, 4\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "for i in range(8):\n",
        "    fig.add_subplot(4,4,i+1)\n",
        "    image = val_data[random_indexes[i]]\n",
        "    plt.imshow(compressor(image)[0].flip(dims=[1]).rot90(1, [0,1]).cpu(), cmap='gray')\n",
        "    plt.title(converter[int(val_labels[random_indexes[i]])])\n",
        "    plt.axis('off')\n",
        "\n",
        "    fig.add_subplot(4,4,i+9)\n",
        "    plt.imshow(image[0].flip(dims=[1]).rot90(1, [0,1]).cpu(), cmap='gray')\n",
        "    plt.title(converter[int(val_labels[random_indexes[i]])])\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "CUzOPOWqir4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### stratcher"
      ],
      "metadata": {
        "id": "MrWBjN571IqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stratcher = torchvision.transforms.RandomAffine(0, scale = (1.05, 1.1))\n",
        "\n",
        "r, c = 4, 4\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "for i in range(8):\n",
        "    fig.add_subplot(4,4,i+1)\n",
        "    image = val_data[random_indexes[i]]\n",
        "    plt.imshow(stratcher(image)[0].flip(dims=[1]).rot90(1, [0,1]).cpu(), cmap='gray')\n",
        "    plt.title(converter[int(val_labels[random_indexes[i]])])\n",
        "    plt.axis('off')\n",
        "\n",
        "    fig.add_subplot(4,4,i+9)\n",
        "    plt.imshow(image[0].flip(dims=[1]).rot90(1, [0,1]).cpu(), cmap='gray')\n",
        "    plt.title(converter[int(val_labels[random_indexes[i]])])\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "q-Ic1tXho8rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## augmeneter"
      ],
      "metadata": {
        "id": "R8UXtO5YpQ5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation = [\n",
        "    perspectiver,\n",
        "    rotater,\n",
        "    shifter,\n",
        "    compressor,\n",
        "    stratcher\n",
        "]\n",
        "augmentation_combinations = []\n",
        "\n",
        "for i in range(1,6):\n",
        "    comb = list(itertools.combinations(augmentation, i))\n",
        "    for j in comb:\n",
        "      if not ((compressor in j) and (stratcher in j)):\n",
        "        augmentation_combinations.append(j)\n",
        "\n",
        "void = transforms.RandomRotation(degrees=(0,0))\n",
        "augmentation_combinations.append([void])\n",
        "augmentation_combinations.append([void])\n",
        "augmentation_combinations.append([void])\n",
        "augmentation_combinations.append([void])\n",
        "augmentation_combinations.append([void])\n",
        "augmentation_combinations.append([void])\n",
        "augmentation_combinations.append([void])\n",
        "augmentation_combinations.append([void])\n",
        "augmentation_pipelines = transforms.RandomChoice([transforms.Compose(list(combination)) for combination in augmentation_combinations])\n",
        "augmentation_pipelines"
      ],
      "metadata": {
        "id": "FIrKuXwnpSrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating dataset"
      ],
      "metadata": {
        "id": "St2xP2vc1gAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = TensorDataset(val_data, val_labels)\n",
        "train_dataset = TensorDataset(train_data, train_labels)\n",
        "train_dev_sets = torch.utils.data.ConcatDataset([train_dataset, val_dataset])\n",
        "test_dataset = TensorDataset(test_data, test_labels)"
      ],
      "metadata": {
        "id": "C2WWdAGC1krs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = [int(i) for j,i in train_dev_sets]\n",
        "\n",
        "count_classes = Counter(targets)\n",
        "class_weights = {i: 1/c for i, c in count_classes.items()}\n",
        "\n",
        "dataset_weights = [0]* len(targets)\n",
        "\n",
        "for i, label in enumerate(bar(targets)):\n",
        "    dataset_weights[i] = class_weights[label]\n",
        "\n",
        "N = max(count_classes.values()) * len(count_classes)\n",
        "\n",
        "sampler = WeightedRandomSampler(dataset_weights, num_samples=N, replacement=True)\n",
        "train_dataloader = DataLoader(train_dev_sets, batch_size=2156, sampler=sampler)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4196, shuffle=True)"
      ],
      "metadata": {
        "id": "ZfdVcRXW3u8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count=Counter()\n",
        "\n",
        "for data, labels in bar(train_dataloader):\n",
        "    count+= Counter(labels.tolist())\n",
        "\n",
        "df = pd.DataFrame(data=count.values(), index=[converter[int(i)] for i in count.keys()], columns=['value'])\n",
        "plt.figure(figsize=(16., 6.))\n",
        "sns.barplot(x=df.index, y='value', data=df)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PWzwWeGE5h8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Epoch fitter"
      ],
      "metadata": {
        "id": "rgIKIKhv57-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_epoch(data, labels, optimizer, device, loss_fn, model):\n",
        "  optimizer.zero_grad()\n",
        "  data = data.to(device)\n",
        "  labels = labels.to(device)\n",
        "\n",
        "  preds = model.forward(data)\n",
        "\n",
        "  loss_val = loss_fn(preds, labels)\n",
        "  loss_val.backward()\n",
        "\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "GYX4BP2l59jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your model (!!!!!!!!!!!!!!!!!)"
      ],
      "metadata": {
        "id": "dw2VBlJnjwRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########################################\n",
        "# class with your model"
      ],
      "metadata": {
        "id": "XkXTVKZWbnpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ########################## YourModel().to(device)\n",
        "summary(model, (1,28,28))"
      ],
      "metadata": {
        "id": "7hsM_tYLn28y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test learning (!!!!!!!!!!!!!!!!!!)"
      ],
      "metadata": {
        "id": "3151CMfYjzDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.nn.CrossEntropyLoss()\n",
        "model = ####################### YourModel().to(device)\n",
        "optimizer = ############################### your optimizer\n",
        "test_accuracy_history = []\n",
        "max_epochs = 100 ########################### May be different number\n",
        "\n",
        "\n",
        "for epoch in bar(range(max_epochs), desc='learning'):\n",
        "  model.train()\n",
        "  for data_batch, labels_batch in bar(train_dataloader, leave=False):\n",
        "    fit_epoch(augmentation_pipelines(data_batch), labels_batch, optimizer, device, loss, model)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    test_acc = 0\n",
        "\n",
        "    for data_batch_test, labels_batch_test in bar(test_dataloader, desc='testing', leave=False):\n",
        "      data_batch_test = data_batch_test.to(device)\n",
        "      labels_batch_test = labels_batch_test.to(device)\n",
        "      test_preds = model.forward(data_batch_test).data\n",
        "\n",
        "      accuracy = (test_preds.argmax(dim=1)==labels_batch_test).float().mean().data.cpu()\n",
        "      test_acc += accuracy / len(test_dataloader)\n",
        "    test_accuracy_history.append(test_acc)\n",
        "\n",
        "send_notification()"
      ],
      "metadata": {
        "id": "Uwdia2yofB8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(data=go.Scatter(x=[i for i in range(max_epochs)], y=test_accuracy_history, mode='lines+markers'))\n",
        "\n",
        "fig.update_layout(title=\"Accuracy during learning\", xaxis_title=\"epoch\", yaxis_title=\"accuracy\")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "YCpG9icv6WVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning model (!!!!!!!!!!!!!!)"
      ],
      "metadata": {
        "id": "FenVvps9oji1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_accuracy = 0.0\n",
        "best_state = None\n",
        "experiments = ############## Minimum 20\n",
        "max_epochs = ########################## your chosen value\n",
        "\n",
        "for experiment in bar(range(experiments), desc='Experimenting', leave=False):\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "    model = ########################### YourModel.to(device)\n",
        "    optimizer = ########################################## your optimzier\n",
        "\n",
        "    for epoch in bar(range(max_epochs), desc='learning', leave = False):\n",
        "        model.train()\n",
        "        for data_batch, labels_batch in bar(train_dataloader, leave=False):\n",
        "            fit_epoch(augmentation_pipelines(data_batch), labels_batch, optimizer, device, loss, model)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            test_acc = 0\n",
        "            for data_batch_test, labels_batch_test in bar(test_dataloader, desc='testing', leave=False):\n",
        "                data_batch_test = data_batch_test.to(device)\n",
        "                labels_batch_test = labels_batch_test.to(device)\n",
        "                test_preds = model.forward(data_batch_test).data\n",
        "\n",
        "                accuracy = (test_preds.argmax(dim=1)==labels_batch_test).float().mean().data.cpu()\n",
        "                test_acc += accuracy / len(test_dataloader)\n",
        "        if test_acc>best_accuracy:\n",
        "            best_accuracy = test_acc\n",
        "            best_state = deepcopy(model.state_dict())\n",
        "            print(\"you have new best accuracy: \", best_accuracy)\n",
        "send_notification(message=\"Операция завершена. Не забудьте сохранить веса на локальном компьютере\")\n",
        "\n"
      ],
      "metadata": {
        "id": "srwTozEColur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and test weights (!!!!!!!!!!!!!!!!!!)"
      ],
      "metadata": {
        "id": "_gMKw3nTqlsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = names[number] + \"_\"+\"ModelParameters\"+str(float(best_accuracy))+\".pth\"\n",
        "\n",
        "torch.save(best_state, filename)\n",
        "model = ########################## YourModel.to(device)\n",
        "model.load_state_dict(torch.load(filename))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  test_acc = 0\n",
        "  for data_batch_test, labels_batch_test in bar(test_dataloader, desc='testing', leave=False):\n",
        "    data_batch_test = data_batch_test.to(device)\n",
        "    labels_batch_test = labels_batch_test.to(device)\n",
        "    test_preds = model.forward(data_batch_test).data\n",
        "\n",
        "    accuracy = (test_preds.argmax(dim=1)==labels_batch_test).float().mean().data.cpu()\n",
        "    test_acc += accuracy / len(test_dataloader)\n",
        "\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "1W1hRVt8qr9b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}